{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir as ld\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv', 'test.csv', 'train.csv']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train datasets** have 42000 records, in which each record has 28\\*28=784 pixels and 1 label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test datasets** have 28000 records and each record consists of 784 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: pixel0, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pixel0'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using iloc to get values of pandas.core.frame.DataFrame object by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel0      0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "           ..\n",
       "pixel779    0\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "Name: 0, Length: 784, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[0,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization using plt.imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=test.values.astype('float32')[0]\n",
    "test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6ce4ed4210>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.reshape(28,28,1))\n",
    "plt.imshow((test.iloc[0,].values).reshape(28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking plan: 1. KNN 2. logistic regression 3. SVM 4. Nural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio=0.9\n",
    "train_size = int(train.shape[0]*split_ratio)\n",
    "train_data_x = (train.iloc[:train_size,1:]).values.astype('float32')\n",
    "train_data_y = (train.iloc[:train_size,0]).values.astype('int32')\n",
    "test_data_x = (train.iloc[train_size:,1:]).values.astype('float32')\n",
    "test_data_y = (train.iloc[train_size:,0]).values.astype('int32')\n",
    "final_test_data = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1000)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=1000)\n",
    "neigh.fit(train_data_x, train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_y_pred = neigh.predict(test_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 3 5 7 9 2 8 9 9]\n"
     ]
    }
   ],
   "source": [
    "print(test_data_y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       455\n",
      "           1       0.61      1.00      0.76       458\n",
      "           2       0.99      0.68      0.80       392\n",
      "           3       0.88      0.85      0.87       448\n",
      "           4       0.96      0.79      0.86       438\n",
      "           5       0.93      0.71      0.81       354\n",
      "           6       0.88      0.94      0.91       413\n",
      "           7       0.90      0.90      0.90       421\n",
      "           8       0.92      0.70      0.79       397\n",
      "           9       0.77      0.87      0.81       424\n",
      "\n",
      "    accuracy                           0.84      4200\n",
      "   macro avg       0.88      0.84      0.85      4200\n",
      "weighted avg       0.87      0.84      0.85      4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(test_data_y,test_data_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunwanx/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(train_data_x, train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_y_pred_logistic = clf.predict(test_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       455\n",
      "           1       0.95      0.97      0.96       458\n",
      "           2       0.90      0.88      0.89       392\n",
      "           3       0.92      0.91      0.92       448\n",
      "           4       0.93      0.92      0.93       438\n",
      "           5       0.91      0.84      0.87       354\n",
      "           6       0.94      0.98      0.96       413\n",
      "           7       0.93      0.95      0.94       421\n",
      "           8       0.84      0.87      0.86       397\n",
      "           9       0.92      0.87      0.89       424\n",
      "\n",
      "    accuracy                           0.92      4200\n",
      "   macro avg       0.92      0.92      0.92      4200\n",
      "weighted avg       0.92      0.92      0.92      4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(test_data_y,test_data_y_pred_logistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-4d1c590d97b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm_model.fit(train_data_x,train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_y_pred_svm  = svm_model.predict(test_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_data_y,test_data_y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_y_onehot = to_categorical(train_data_y)\n",
    "test_data_y_onehot = to_categorical(test_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just your regular densely-connected NN layer.\n",
      "\n",
      "  `Dense` implements the operation:\n",
      "  `output = activation(dot(input, kernel) + bias)`\n",
      "  where `activation` is the element-wise activation function\n",
      "  passed as the `activation` argument, `kernel` is a weights matrix\n",
      "  created by the layer, and `bias` is a bias vector created by the layer\n",
      "  (only applicable if `use_bias` is `True`).\n",
      "\n",
      "  Note: If the input to the layer has a rank greater than 2, then `Dense`\n",
      "  computes the dot product between the `inputs` and the `kernel` along the\n",
      "  last axis of the `inputs` and axis 1 of the `kernel` (using `tf.tensordot`).\n",
      "  For example, if input has dimensions `(batch_size, d0, d1)`,\n",
      "  then we create a `kernel` with shape `(d1, units)`, and the `kernel` operates\n",
      "  along axis 2 of the `input`, on every sub-tensor of shape `(1, 1, d1)`\n",
      "  (there are `batch_size * d0` such sub-tensors).\n",
      "  The output in this case will have shape `(batch_size, d0, units)`.\n",
      "\n",
      "  Besides, layer attributes cannot be modified after the layer has been called\n",
      "  once (except the `trainable` attribute).\n",
      "\n",
      "  Example:\n",
      "\n",
      "  >>> # Create a `Sequential` model and add a Dense layer as the first layer.\n",
      "  >>> model = tf.keras.models.Sequential()\n",
      "  >>> model.add(tf.keras.Input(shape=(16,)))\n",
      "  >>> model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
      "  >>> # Now the model will take as input arrays of shape (None, 16)\n",
      "  >>> # and output arrays of shape (None, 32).\n",
      "  >>> # Note that after the first layer, you don't need to specify\n",
      "  >>> # the size of the input anymore:\n",
      "  >>> model.add(tf.keras.layers.Dense(32))\n",
      "  >>> model.output_shape\n",
      "  (None, 32)\n",
      "\n",
      "  Arguments:\n",
      "    units: Positive integer, dimensionality of the output space.\n",
      "    activation: Activation function to use.\n",
      "      If you don't specify anything, no activation is applied\n",
      "      (ie. \"linear\" activation: `a(x) = x`).\n",
      "    use_bias: Boolean, whether the layer uses a bias vector.\n",
      "    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      "    bias_initializer: Initializer for the bias vector.\n",
      "    kernel_regularizer: Regularizer function applied to\n",
      "      the `kernel` weights matrix.\n",
      "    bias_regularizer: Regularizer function applied to the bias vector.\n",
      "    activity_regularizer: Regularizer function applied to\n",
      "      the output of the layer (its \"activation\").\n",
      "    kernel_constraint: Constraint function applied to\n",
      "      the `kernel` weights matrix.\n",
      "    bias_constraint: Constraint function applied to the bias vector.\n",
      "\n",
      "  Input shape:\n",
      "    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      "    The most common situation would be\n",
      "    a 2D input with shape `(batch_size, input_dim)`.\n",
      "\n",
      "  Output shape:\n",
      "    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      "    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      "    the output would have shape `(batch_size, units)`.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(Dense.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 1.8418 - accuracy: 0.4484 - val_loss: 1.4725 - val_accuracy: 0.5060\n",
      "Epoch 2/3\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 1.3018 - accuracy: 0.6110 - val_loss: 1.1670 - val_accuracy: 0.6787\n",
      "Epoch 3/3\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 1.0545 - accuracy: 0.6975 - val_loss: 0.9495 - val_accuracy: 0.7388\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9488 - accuracy: 0.7462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9487940669059753, 0.7461904883384705]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(10,activation='sigmoid',input_shape=(784,)))\n",
    "model.add(Dense(10,activation='sigmoid'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "           loss='categorical_crossentropy', \n",
    "           metrics=['accuracy'])\n",
    "model.fit(train_data_x,train_data_y_onehot,validation_split=0.2, epochs=3)\n",
    "model.evaluate(test_data_x,test_data_y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 1.9050 - accuracy: 0.4646 - val_loss: 1.5144 - val_accuracy: 0.6217\n",
      "Epoch 2/5\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 1.2545 - accuracy: 0.6698 - val_loss: 1.0860 - val_accuracy: 0.7007\n",
      "Epoch 3/5\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 0.9788 - accuracy: 0.7046 - val_loss: 0.8836 - val_accuracy: 0.7266\n",
      "Epoch 4/5\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 0.8496 - accuracy: 0.7390 - val_loss: 0.8214 - val_accuracy: 0.7422\n",
      "Epoch 5/5\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 0.7754 - accuracy: 0.7646 - val_loss: 0.7312 - val_accuracy: 0.7858\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.7580 - accuracy: 0.7755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7579656839370728, 0.7754762172698975]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(10,activation='sigmoid',input_shape=(784,)))\n",
    "model.add(Dense(10,activation='sigmoid'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "           loss='categorical_crossentropy', \n",
    "           metrics=['accuracy'])\n",
    "model.fit(train_data_x,train_data_y_onehot,validation_split=0.2, epochs=5)\n",
    "model.evaluate(test_data_x,test_data_y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "945/945 [==============================] - 2s 3ms/step - loss: 2.2987 - accuracy: 0.2300 - val_loss: 1.9153 - val_accuracy: 0.2810\n",
      "Epoch 2/3\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 1.8034 - accuracy: 0.3115 - val_loss: 1.6658 - val_accuracy: 0.3519\n",
      "Epoch 3/3\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 1.5712 - accuracy: 0.3772 - val_loss: 1.4843 - val_accuracy: 0.3718\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4930 - accuracy: 0.3714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4930205345153809, 0.37142857909202576]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(10,activation='relu',input_shape=(784,)))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "           loss='categorical_crossentropy', \n",
    "           metrics=['accuracy'])\n",
    "model.fit(train_data_x,train_data_y_onehot,validation_split=0.2, epochs=3)\n",
    "model.evaluate(test_data_x,test_data_y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN + normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 1.8787 - accuracy: 0.4569 - val_loss: 1.4940 - val_accuracy: 0.5593\n",
      "Epoch 2/3\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 1.2565 - accuracy: 0.6724 - val_loss: 1.0988 - val_accuracy: 0.7187\n",
      "Epoch 3/3\n",
      "945/945 [==============================] - 2s 2ms/step - loss: 0.9832 - accuracy: 0.7435 - val_loss: 0.8641 - val_accuracy: 0.7726\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.8681 - accuracy: 0.7764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8681401610374451, 0.7764285802841187]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_x_norm = train_data_x-train_data_x.mean()/train_data_x.std()\n",
    "test_data_x_norm = test_data_x-test_data_x.mean()/test_data_x.std()\n",
    "model=Sequential()\n",
    "model.add(Dense(10,activation='sigmoid',input_shape=(784,)))\n",
    "model.add(Dense(10,activation='sigmoid'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "           loss='categorical_crossentropy', \n",
    "           metrics=['accuracy'])\n",
    "model.fit(train_data_x_norm,train_data_y_onehot,validation_split=0.2, epochs=3)\n",
    "model.evaluate(test_data_x_norm,test_data_y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "303/303 [==============================] - 5s 15ms/step - loss: 0.6700 - accuracy: 0.8228 - val_loss: 0.3215 - val_accuracy: 0.9189\n",
      "Epoch 2/3\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.2811 - accuracy: 0.9214 - val_loss: 0.2618 - val_accuracy: 0.9222\n",
      "Epoch 3/3\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.2135 - accuracy: 0.9387 - val_loss: 0.1842 - val_accuracy: 0.9483\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.1910 - accuracy: 0.9445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19100730121135712, 0.944523811340332]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "#model.add(Dense(10,input_shape=(28,28,1)))\n",
    "model.add(Conv2D(10,kernel_size=3,activation='sigmoid',input_shape=(28,28,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_data_x_norm.reshape(train_data_x_norm.shape[0],28,28,1),train_data_y_onehot,validation_split=0.2,epochs=3,batch_size=100)\n",
    "model.evaluate(test_data_x_norm.reshape(test_data_x_norm.shape[0],28,28,1),test_data_y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "303/303 [==============================] - 47s 156ms/step - loss: 1.2831 - accuracy: 0.8854 - val_loss: 0.1338 - val_accuracy: 0.9595\n",
      "Epoch 2/20\n",
      "303/303 [==============================] - 48s 158ms/step - loss: 0.0915 - accuracy: 0.9725 - val_loss: 0.0901 - val_accuracy: 0.9733\n",
      "Epoch 3/20\n",
      "303/303 [==============================] - 46s 151ms/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.0896 - val_accuracy: 0.9749\n",
      "Epoch 4/20\n",
      "303/303 [==============================] - 44s 146ms/step - loss: 0.0489 - accuracy: 0.9846 - val_loss: 0.0678 - val_accuracy: 0.9790\n",
      "Epoch 5/20\n",
      "303/303 [==============================] - 47s 154ms/step - loss: 0.0400 - accuracy: 0.9879 - val_loss: 0.0791 - val_accuracy: 0.9780\n",
      "Epoch 6/20\n",
      "303/303 [==============================] - 43s 141ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 0.0808 - val_accuracy: 0.9788\n",
      "Epoch 7/20\n",
      "303/303 [==============================] - 43s 142ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0655 - val_accuracy: 0.9840\n",
      "Epoch 8/20\n",
      "303/303 [==============================] - 43s 140ms/step - loss: 0.0289 - accuracy: 0.9916 - val_loss: 0.0751 - val_accuracy: 0.9815\n",
      "Epoch 9/20\n",
      "303/303 [==============================] - 43s 140ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 0.0774 - val_accuracy: 0.9825\n",
      "Epoch 10/20\n",
      "303/303 [==============================] - 43s 142ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.0927 - val_accuracy: 0.9800\n",
      "Epoch 11/20\n",
      "303/303 [==============================] - 45s 150ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.1006 - val_accuracy: 0.9799\n",
      "Epoch 12/20\n",
      "303/303 [==============================] - 43s 142ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0806 - val_accuracy: 0.9853\n",
      "Epoch 13/20\n",
      "303/303 [==============================] - 43s 140ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.0825 - val_accuracy: 0.9836\n",
      "Epoch 14/20\n",
      "303/303 [==============================] - 44s 147ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.0941 - val_accuracy: 0.9823\n",
      "Epoch 15/20\n",
      "303/303 [==============================] - 42s 139ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 0.1196 - val_accuracy: 0.9800\n",
      "Epoch 16/20\n",
      "303/303 [==============================] - 43s 142ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0961 - val_accuracy: 0.9824\n",
      "Epoch 17/20\n",
      "303/303 [==============================] - 43s 142ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0986 - val_accuracy: 0.9807\n",
      "Epoch 18/20\n",
      "303/303 [==============================] - 43s 143ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.0917 - val_accuracy: 0.9844\n",
      "Epoch 19/20\n",
      "303/303 [==============================] - 44s 144ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.1046 - val_accuracy: 0.9837\n",
      "Epoch 20/20\n",
      "303/303 [==============================] - 43s 144ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.1194 - val_accuracy: 0.9836\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0852 - accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08524676412343979, 0.9819047451019287]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "#model.add(Dense(10,input_shape=(28,28,1)))\n",
    "model.add(Conv2D(100,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(100,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "#model.add(Conv2D(100,kernel_size=(4,4),activation='sigmoid',input_shape=(28,28,1)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(100,activation='sigmoid'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_data_x_norm.reshape(train_data_x_norm.shape[0],28,28,1),train_data_y_onehot,validation_split=0.2,epochs=20,batch_size=100)\n",
    "model.evaluate(test_data_x_norm.reshape(test_data_x_norm.shape[0],28,28,1),test_data_y_onehot,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(test.values.astype('float32').reshape(test.shape[0],28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"DR.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
